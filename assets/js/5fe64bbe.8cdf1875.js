"use strict";(self.webpackChunklucas_cruz=self.webpackChunklucas_cruz||[]).push([[1602],{9962:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>a,contentTitle:()=>c,default:()=>p,frontMatter:()=>o,metadata:()=>s,toc:()=>l});var r=n(4848),i=n(8453);const o={title:"12. Policy Gradient Methods",sidebar_position:12,slug:"/rl-intro-pg"},c="Policy Gradient Methods",s={id:"wiki/reinforcement-learning/intro-to-rl/chapter-12",title:"12. Policy Gradient Methods",description:"In this chapter, you'll learn about:",source:"@site/docs/wiki/reinforcement-learning/1-intro-to-rl/chapter-12.mdx",sourceDirName:"wiki/reinforcement-learning/1-intro-to-rl",slug:"/rl-intro-pg",permalink:"/rl-intro-pg",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:12,frontMatter:{title:"12. Policy Gradient Methods",sidebar_position:12,slug:"/rl-intro-pg"},sidebar:"RLSidebar",previous:{title:"11. (WIP) Eligibility Traces",permalink:"/rl-intro-traces"}},a={},l=[{value:"Recap",id:"recap",level:2}];function d(e){const t={admonition:"admonition",h1:"h1",h2:"h2",header:"header",p:"p",...(0,i.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(t.header,{children:(0,r.jsx)(t.h1,{id:"policy-gradient-methods",children:"Policy Gradient Methods"})}),"\n",(0,r.jsx)(t.admonition,{type:"info",children:(0,r.jsx)(t.p,{children:"In this chapter, you'll learn about:"})}),"\n",(0,r.jsx)(t.h2,{id:"recap",children:"Recap"}),"\n",(0,r.jsx)(t.p,{children:"In this chapter, we've covered:"})]})}function p(e={}){const{wrapper:t}={...(0,i.R)(),...e.components};return t?(0,r.jsx)(t,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},8453:(e,t,n)=>{n.d(t,{R:()=>c,x:()=>s});var r=n(6540);const i={},o=r.createContext(i);function c(e){const t=r.useContext(o);return r.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function s(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:c(e.components),r.createElement(o.Provider,{value:t},e.children)}}}]);