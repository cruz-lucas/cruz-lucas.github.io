"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[567],{5226:e=>{e.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"MLSidebar":[{"type":"category","label":"Designing Machine Learning Systems","items":[{"type":"link","label":"Chapter 1","href":"/machine-learning/ml-systems/chapter-1","docId":"machine-learning/ml-systems/chapter-1","unlisted":false}],"collapsed":true,"collapsible":true}],"RLSidebar":[{"type":"category","label":"Foundations on Deep Reinforcement Learning","items":[{"type":"link","label":"Foundations on Reinforcement Learning","href":"/reinforcement-learning/foundations-drl/foundations","docId":"reinforcement-learning/foundations-drl/foundations","unlisted":false}],"collapsed":true,"collapsible":true}],"StatsSidebar":[{"type":"link","label":"(Not that) Basic Statistical Concepts","href":"/statistics/basic-statistics/","docId":"statistics/basic-statistics/index","unlisted":false},{"type":"link","label":"A Practical Guide to Experimentation","href":"/statistics/experimentation/","docId":"statistics/experimentation/index","unlisted":false}]},"docs":{"about/CV":{"id":"about/CV","title":"Curriculum Vitae","description":"Senior Machine Learning Engineer"},"about/index":{"id":"about/index","title":"About Me","description":""},"about/projects":{"id":"about/projects","title":"Projects","description":"WIP"},"learning/index":{"id":"learning/index","title":"Learning","description":""},"machine-learning/ml-systems/chapter-1":{"id":"machine-learning/ml-systems/chapter-1","title":"Chapter 1","description":"","sidebar":"MLSidebar"},"reinforcement-learning/foundations-drl/foundations":{"id":"reinforcement-learning/foundations-drl/foundations","title":"Foundations on Reinforcement Learning","description":"This lecture covers Markov Decision Processes (MDPs) and exact solution methods, laying the groundwork for understanding key concepts. We\'ll define the main components of MDPs\u2014states, actions, transition probabilities, and rewards\u2014and look at exact solution methods like dynamic programming. While these methods work well for small-scale problems, they don\'t scale effectively to larger ones, pointing to the need for advanced techniques that we\'ll discuss in later lectures. We\'ll also introduce the maximum entropy formulation, an approach that improves exploration and robustness in reinforcement learning (RL) agents.","sidebar":"RLSidebar"},"reinforcement-learning/intro-to-rl/chapter-1":{"id":"reinforcement-learning/intro-to-rl/chapter-1","title":"Chapter 1","description":""},"statistics/basic-statistics/index":{"id":"statistics/basic-statistics/index","title":"(Not that) Basic Statistical Concepts","description":"","sidebar":"StatsSidebar"},"statistics/experimentation/index":{"id":"statistics/experimentation/index","title":"A Practical Guide to Experimentation","description":"","sidebar":"StatsSidebar"}}}}')}}]);